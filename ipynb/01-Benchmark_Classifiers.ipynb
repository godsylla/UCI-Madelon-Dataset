{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed Unprocessed Data into Classifiers, Score, and Measure Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "import matplotlib.pyplot as plt, seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC \n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Data from Pickled DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/madelon/ipynb'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "cook_total_sample = pd.read_pickle('../assets/pickled_samples/cook_total_samples.p')\n",
    "madelon_train_sample = pd.read_pickle('../assets/pickled_samples/madelon_sample_train.p')\n",
    "madelon_train_sample_label = pd.read_pickle('../assets/pickled_samples/madelon_sample_train_labels.p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Madelon:** It's not necessary to load in the test set since that's the hold out data to test the classification model's accuracy. Train/test/split on the training data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Data through the Classifiers and obtain Train & Test scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Madelon Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>490</th>\n",
       "      <th>491</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>479</td>\n",
       "      <td>438</td>\n",
       "      <td>533</td>\n",
       "      <td>490</td>\n",
       "      <td>485</td>\n",
       "      <td>479</td>\n",
       "      <td>493</td>\n",
       "      <td>479</td>\n",
       "      <td>504</td>\n",
       "      <td>483</td>\n",
       "      <td>...</td>\n",
       "      <td>477</td>\n",
       "      <td>472</td>\n",
       "      <td>495</td>\n",
       "      <td>564</td>\n",
       "      <td>474</td>\n",
       "      <td>516</td>\n",
       "      <td>482</td>\n",
       "      <td>469</td>\n",
       "      <td>574</td>\n",
       "      <td>482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>478</td>\n",
       "      <td>476</td>\n",
       "      <td>514</td>\n",
       "      <td>491</td>\n",
       "      <td>619</td>\n",
       "      <td>471</td>\n",
       "      <td>565</td>\n",
       "      <td>475</td>\n",
       "      <td>482</td>\n",
       "      <td>475</td>\n",
       "      <td>...</td>\n",
       "      <td>465</td>\n",
       "      <td>480</td>\n",
       "      <td>469</td>\n",
       "      <td>745</td>\n",
       "      <td>455</td>\n",
       "      <td>460</td>\n",
       "      <td>474</td>\n",
       "      <td>475</td>\n",
       "      <td>548</td>\n",
       "      <td>550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1422</th>\n",
       "      <td>481</td>\n",
       "      <td>492</td>\n",
       "      <td>475</td>\n",
       "      <td>479</td>\n",
       "      <td>527</td>\n",
       "      <td>480</td>\n",
       "      <td>508</td>\n",
       "      <td>474</td>\n",
       "      <td>480</td>\n",
       "      <td>475</td>\n",
       "      <td>...</td>\n",
       "      <td>477</td>\n",
       "      <td>482</td>\n",
       "      <td>501</td>\n",
       "      <td>603</td>\n",
       "      <td>433</td>\n",
       "      <td>524</td>\n",
       "      <td>476</td>\n",
       "      <td>490</td>\n",
       "      <td>467</td>\n",
       "      <td>532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>472</td>\n",
       "      <td>424</td>\n",
       "      <td>493</td>\n",
       "      <td>478</td>\n",
       "      <td>464</td>\n",
       "      <td>479</td>\n",
       "      <td>504</td>\n",
       "      <td>474</td>\n",
       "      <td>493</td>\n",
       "      <td>471</td>\n",
       "      <td>...</td>\n",
       "      <td>450</td>\n",
       "      <td>475</td>\n",
       "      <td>482</td>\n",
       "      <td>520</td>\n",
       "      <td>517</td>\n",
       "      <td>527</td>\n",
       "      <td>476</td>\n",
       "      <td>515</td>\n",
       "      <td>501</td>\n",
       "      <td>504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>473</td>\n",
       "      <td>435</td>\n",
       "      <td>534</td>\n",
       "      <td>485</td>\n",
       "      <td>504</td>\n",
       "      <td>482</td>\n",
       "      <td>483</td>\n",
       "      <td>475</td>\n",
       "      <td>488</td>\n",
       "      <td>480</td>\n",
       "      <td>...</td>\n",
       "      <td>484</td>\n",
       "      <td>479</td>\n",
       "      <td>532</td>\n",
       "      <td>645</td>\n",
       "      <td>513</td>\n",
       "      <td>549</td>\n",
       "      <td>472</td>\n",
       "      <td>497</td>\n",
       "      <td>536</td>\n",
       "      <td>448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1    2    3    4    5    6    7    8    9   ...   490  491  492  \\\n",
       "138   479  438  533  490  485  479  493  479  504  483 ...   477  472  495   \n",
       "472   478  476  514  491  619  471  565  475  482  475 ...   465  480  469   \n",
       "1422  481  492  475  479  527  480  508  474  480  475 ...   477  482  501   \n",
       "162   472  424  493  478  464  479  504  474  493  471 ...   450  475  482   \n",
       "277   473  435  534  485  504  482  483  475  488  480 ...   484  479  532   \n",
       "\n",
       "      493  494  495  496  497  498  499  \n",
       "138   564  474  516  482  469  574  482  \n",
       "472   745  455  460  474  475  548  550  \n",
       "1422  603  433  524  476  490  467  532  \n",
       "162   520  517  527  476  515  501  504  \n",
       "277   645  513  549  472  497  536  448  \n",
       "\n",
       "[5 rows x 500 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "madelon_train_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 500)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "madelon_train_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600,)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "madelon_train_sample_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mad_X_train, mad_X_test, mad_y_train, mad_y_test = train_test_split(madelon_train_sample,\\\n",
    "                                                                    madelon_train_sample_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(450, 500)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(150, 500)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(450,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(mad_X_train.shape)\n",
    "display(mad_X_test.shape)\n",
    "display(mad_y_train.shape)\n",
    "display(mad_y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Madelon Dataset (Raw Benchmarking without any Preprocessing)\n",
    "Uses the out of the box default parameters provided by `sklearn` for the selected classification models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names_of_classifiers = ['LogisticRegression', 'KNeighbors', 'DecisionTree', 'SVClassifier']\n",
    "\n",
    "classifiers = [\n",
    "    LogisticRegression(n_jobs=-1, random_state=42),\n",
    "    KNeighborsClassifier(n_jobs=-1),\n",
    "    DecisionTreeClassifier(random_state=42),\n",
    "    SVC(random_state=42)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the results in a dictionary to subsequenty be able to throw the results to compare into a pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mad_raw_test_scores = {}\n",
    "mad_raw_train_scores = {}\n",
    "mad_raw_y_preds = {}\n",
    "\n",
    "for name, clfr in zip(names_of_classifiers, classifiers):\n",
    "    clfr.fit(mad_X_train, mad_y_train)\n",
    "    \n",
    "    train_score = clfr.score(mad_X_train, mad_y_train)\n",
    "    test_score = clfr.score(mad_X_test, mad_y_test)\n",
    "    y_pred = clfr.predict(mad_X_test)\n",
    "    \n",
    "    mad_raw_train_scores[name] = train_score\n",
    "    mad_raw_test_scores[name] = test_score\n",
    "    mad_raw_y_preds[name] = y_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DecisionTree': 0.59999999999999998,\n",
       " 'KNeighbors': 0.71333333333333337,\n",
       " 'LogisticRegression': 0.62,\n",
       " 'SVClassifier': 0.64666666666666661}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mad_raw_test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DecisionTree': 1.0,\n",
       " 'KNeighbors': 0.82222222222222219,\n",
       " 'LogisticRegression': 1.0,\n",
       " 'SVClassifier': 1.0}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mad_raw_train_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DecisionTree': array([ 1,  1,  1,  1,  1, -1, -1,  1,  1,  1,  1,  1,  1,  1, -1, -1, -1,\n",
       "        -1, -1, -1, -1,  1,  1, -1, -1, -1,  1, -1, -1, -1,  1,  1, -1,  1,\n",
       "        -1,  1,  1,  1,  1,  1,  1,  1, -1,  1, -1,  1, -1, -1,  1, -1,  1,\n",
       "        -1, -1, -1,  1, -1, -1,  1,  1,  1, -1, -1,  1,  1,  1, -1, -1,  1,\n",
       "        -1,  1,  1, -1, -1,  1, -1,  1, -1,  1,  1,  1, -1, -1,  1, -1, -1,\n",
       "        -1, -1,  1,  1,  1,  1, -1, -1,  1, -1,  1, -1,  1,  1,  1, -1, -1,\n",
       "         1,  1,  1, -1,  1, -1,  1,  1,  1, -1,  1,  1,  1,  1, -1,  1,  1,\n",
       "        -1,  1,  1,  1,  1,  1,  1, -1, -1,  1, -1,  1, -1, -1, -1, -1,  1,\n",
       "         1, -1, -1, -1, -1,  1, -1, -1, -1, -1, -1,  1,  1, -1]),\n",
       " 'KNeighbors': array([-1,  1, -1, -1,  1,  1, -1,  1, -1,  1, -1,  1,  1, -1, -1, -1,  1,\n",
       "        -1,  1, -1, -1, -1, -1,  1, -1, -1, -1, -1,  1,  1, -1,  1, -1,  1,\n",
       "         1, -1,  1, -1, -1,  1,  1,  1, -1,  1, -1, -1, -1,  1,  1,  1,  1,\n",
       "        -1, -1, -1, -1, -1, -1,  1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "        -1,  1, -1, -1, -1, -1,  1,  1, -1, -1, -1, -1, -1, -1,  1, -1,  1,\n",
       "        -1,  1, -1,  1,  1,  1, -1, -1,  1, -1,  1,  1,  1,  1, -1,  1, -1,\n",
       "         1, -1,  1,  1, -1, -1,  1, -1, -1,  1, -1, -1, -1, -1,  1,  1, -1,\n",
       "        -1,  1, -1,  1, -1,  1, -1, -1, -1,  1, -1,  1,  1, -1, -1,  1,  1,\n",
       "        -1, -1, -1, -1, -1, -1,  1, -1, -1, -1,  1,  1, -1, -1]),\n",
       " 'LogisticRegression': array([ 1, -1, -1,  1,  1, -1, -1,  1, -1,  1,  1,  1, -1,  1, -1, -1,  1,\n",
       "        -1,  1, -1, -1, -1,  1, -1,  1, -1,  1,  1,  1, -1, -1,  1,  1, -1,\n",
       "        -1,  1, -1,  1,  1,  1,  1, -1,  1,  1, -1, -1, -1, -1, -1,  1,  1,\n",
       "         1,  1, -1, -1,  1, -1,  1,  1, -1, -1, -1,  1,  1, -1, -1, -1, -1,\n",
       "         1,  1,  1,  1, -1,  1, -1, -1,  1, -1,  1,  1,  1, -1, -1,  1,  1,\n",
       "         1,  1,  1,  1, -1, -1, -1, -1,  1, -1, -1, -1, -1, -1,  1,  1,  1,\n",
       "         1, -1,  1,  1,  1, -1,  1, -1,  1, -1, -1,  1,  1, -1,  1,  1,  1,\n",
       "        -1, -1, -1,  1,  1,  1,  1,  1, -1,  1, -1,  1, -1, -1, -1, -1,  1,\n",
       "        -1, -1,  1, -1, -1, -1,  1,  1, -1,  1, -1,  1,  1, -1]),\n",
       " 'SVClassifier': array([-1, -1, -1, -1, -1, -1, -1,  1, -1,  1, -1,  1, -1, -1, -1, -1, -1,\n",
       "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1, -1, -1,\n",
       "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "        -1,  1, -1, -1, -1,  1, -1, -1, -1, -1,  1, -1, -1, -1, -1, -1, -1,\n",
       "        -1, -1,  1,  1, -1, -1, -1, -1,  1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         1, -1, -1, -1,  1, -1, -1, -1, -1, -1, -1, -1,  1, -1, -1, -1,  1,\n",
       "        -1, -1, -1,  1, -1, -1, -1, -1, -1, -1, -1,  1, -1, -1, -1, -1, -1,\n",
       "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1, -1, -1])}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mad_raw_y_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cook Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>feat_000</th>\n",
       "      <th>feat_001</th>\n",
       "      <th>feat_002</th>\n",
       "      <th>feat_003</th>\n",
       "      <th>feat_004</th>\n",
       "      <th>feat_005</th>\n",
       "      <th>feat_006</th>\n",
       "      <th>feat_007</th>\n",
       "      <th>feat_008</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_991</th>\n",
       "      <th>feat_992</th>\n",
       "      <th>feat_993</th>\n",
       "      <th>feat_994</th>\n",
       "      <th>feat_995</th>\n",
       "      <th>feat_996</th>\n",
       "      <th>feat_997</th>\n",
       "      <th>feat_998</th>\n",
       "      <th>feat_999</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>116031</td>\n",
       "      <td>-0.063592</td>\n",
       "      <td>-0.935132</td>\n",
       "      <td>-0.788636</td>\n",
       "      <td>2.006542</td>\n",
       "      <td>0.057752</td>\n",
       "      <td>-0.612374</td>\n",
       "      <td>-0.319290</td>\n",
       "      <td>-0.130704</td>\n",
       "      <td>-0.426335</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079754</td>\n",
       "      <td>-0.609663</td>\n",
       "      <td>1.101417</td>\n",
       "      <td>-0.485404</td>\n",
       "      <td>0.085902</td>\n",
       "      <td>-0.780068</td>\n",
       "      <td>0.155906</td>\n",
       "      <td>0.241406</td>\n",
       "      <td>0.538386</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24415</td>\n",
       "      <td>-0.452243</td>\n",
       "      <td>0.258384</td>\n",
       "      <td>0.620509</td>\n",
       "      <td>0.389080</td>\n",
       "      <td>-0.197159</td>\n",
       "      <td>0.829617</td>\n",
       "      <td>-0.059411</td>\n",
       "      <td>0.910375</td>\n",
       "      <td>-0.323078</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.634202</td>\n",
       "      <td>0.556551</td>\n",
       "      <td>2.037437</td>\n",
       "      <td>-0.482600</td>\n",
       "      <td>-1.418812</td>\n",
       "      <td>0.079200</td>\n",
       "      <td>-0.368648</td>\n",
       "      <td>0.219643</td>\n",
       "      <td>-0.108730</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>115872</td>\n",
       "      <td>1.073645</td>\n",
       "      <td>-1.015950</td>\n",
       "      <td>-0.355322</td>\n",
       "      <td>0.452687</td>\n",
       "      <td>-0.744907</td>\n",
       "      <td>-0.776871</td>\n",
       "      <td>0.385545</td>\n",
       "      <td>0.576864</td>\n",
       "      <td>-0.339835</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.270593</td>\n",
       "      <td>0.250330</td>\n",
       "      <td>0.173127</td>\n",
       "      <td>-0.673090</td>\n",
       "      <td>-0.450532</td>\n",
       "      <td>1.538424</td>\n",
       "      <td>0.276987</td>\n",
       "      <td>-0.257989</td>\n",
       "      <td>-0.351097</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62456</td>\n",
       "      <td>-0.269215</td>\n",
       "      <td>1.790995</td>\n",
       "      <td>-0.171136</td>\n",
       "      <td>0.258013</td>\n",
       "      <td>-0.215587</td>\n",
       "      <td>-0.516337</td>\n",
       "      <td>-0.228766</td>\n",
       "      <td>-0.446238</td>\n",
       "      <td>0.418390</td>\n",
       "      <td>...</td>\n",
       "      <td>0.773900</td>\n",
       "      <td>-0.321531</td>\n",
       "      <td>0.847676</td>\n",
       "      <td>-1.532333</td>\n",
       "      <td>-0.613422</td>\n",
       "      <td>-1.498944</td>\n",
       "      <td>-1.059311</td>\n",
       "      <td>0.628973</td>\n",
       "      <td>-0.830657</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>173909</td>\n",
       "      <td>0.398804</td>\n",
       "      <td>0.579328</td>\n",
       "      <td>-0.905363</td>\n",
       "      <td>-0.124140</td>\n",
       "      <td>-0.545298</td>\n",
       "      <td>0.409123</td>\n",
       "      <td>-0.179135</td>\n",
       "      <td>0.275275</td>\n",
       "      <td>-0.253539</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.643034</td>\n",
       "      <td>-0.752793</td>\n",
       "      <td>0.176453</td>\n",
       "      <td>0.234722</td>\n",
       "      <td>1.122761</td>\n",
       "      <td>-1.139794</td>\n",
       "      <td>1.231819</td>\n",
       "      <td>-0.783419</td>\n",
       "      <td>1.448478</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1002 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      _id  feat_000  feat_001  feat_002  feat_003  feat_004  feat_005  \\\n",
       "0  116031 -0.063592 -0.935132 -0.788636  2.006542  0.057752 -0.612374   \n",
       "1   24415 -0.452243  0.258384  0.620509  0.389080 -0.197159  0.829617   \n",
       "2  115872  1.073645 -1.015950 -0.355322  0.452687 -0.744907 -0.776871   \n",
       "3   62456 -0.269215  1.790995 -0.171136  0.258013 -0.215587 -0.516337   \n",
       "4  173909  0.398804  0.579328 -0.905363 -0.124140 -0.545298  0.409123   \n",
       "\n",
       "   feat_006  feat_007  feat_008   ...    feat_991  feat_992  feat_993  \\\n",
       "0 -0.319290 -0.130704 -0.426335   ...    0.079754 -0.609663  1.101417   \n",
       "1 -0.059411  0.910375 -0.323078   ...   -0.634202  0.556551  2.037437   \n",
       "2  0.385545  0.576864 -0.339835   ...   -0.270593  0.250330  0.173127   \n",
       "3 -0.228766 -0.446238  0.418390   ...    0.773900 -0.321531  0.847676   \n",
       "4 -0.179135  0.275275 -0.253539   ...   -0.643034 -0.752793  0.176453   \n",
       "\n",
       "   feat_994  feat_995  feat_996  feat_997  feat_998  feat_999  target  \n",
       "0 -0.485404  0.085902 -0.780068  0.155906  0.241406  0.538386       1  \n",
       "1 -0.482600 -1.418812  0.079200 -0.368648  0.219643 -0.108730       1  \n",
       "2 -0.673090 -0.450532  1.538424  0.276987 -0.257989 -0.351097       1  \n",
       "3 -1.532333 -0.613422 -1.498944 -1.059311  0.628973 -0.830657       0  \n",
       "4  0.234722  1.122761 -1.139794  1.231819 -0.783419  1.448478       1  \n",
       "\n",
       "[5 rows x 1002 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cook_total_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "cook_target = cook_total_sample['target']\n",
    "cook_features = cook_total_sample.drop(['_id', 'target'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6600,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(6600, 1000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(cook_target.shape)\n",
    "display(cook_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cook_X_train, cook_X_test, cook_y_train, cook_y_test = train_test_split(cook_features, cook_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_log_loss (y_true, y_pred):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
